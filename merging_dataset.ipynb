{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "33adf3a1-49c0-47f1-9c56-2f0e75d67a2f",
   "metadata": {},
   "source": [
    "## We need to merge all the different article files together ##"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "287e4605-dbc3-4162-ad86-d02be637633e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "#first we need to load and merge all article files\n",
    "article_files = [\n",
    "    \"articles_1_10.csv\", \"articles_11_20.csv\", \"articles_21_30.csv\",\n",
    "    \"articles_31_40.csv\", \"articles_41_50.csv\", \"articles_51_55.csv\",\n",
    "    \"articles_56_60.csv\", \"articles_61_68.csv\"\n",
    "]\n",
    "\n",
    "article_dfs = [pd.read_csv(file) for file in article_files]\n",
    "all_articles = pd.concat(article_dfs, ignore_index=True)\n",
    "all_articles = all_articles.dropna(subset=['article_text'])\n",
    "all_articles = all_articles.drop_duplicates(subset='article_url')\n",
    "\n",
    "#and the save the final articles file\n",
    "all_articles.to_csv(\"articles_2016_2024.csv\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "73bf1a19-e619-4e91-9cbd-b03f5164bd8f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2554"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(all_articles)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "49829ed2-5723-4f62-8787-32b1f662a01c",
   "metadata": {},
   "outputs": [],
   "source": [
    "#then load and merge all comment files\n",
    "comment_files = [\n",
    "    \"comments_1_10.csv\", \"comments_11_20.csv\", \"comments_21_30.csv\",\n",
    "    \"comments_31_40.csv\", \"comments_41_50.csv\", \"comments_51_55.csv\",\n",
    "    \"comments_56_60.csv\", \"comments_61_68.csv\"\n",
    "]\n",
    "\n",
    "comment_dfs = [pd.read_csv(file) for file in comment_files]\n",
    "all_comments = pd.concat(comment_dfs, ignore_index=True)\n",
    "all_comments = all_comments.drop_duplicates(subset=['article_url', 'comment_text'])\n",
    "\n",
    "#and the save the final comment file\n",
    "all_comments.to_csv(\"comments_2016_2024.csv\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "6052237f-f8a5-434f-977e-d38b33598a3f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "80729"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(all_comments)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
